{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet langchain_experimental langchain_openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "test_input_text =r\"\"\"Le peuple va s’exprimer les 30 juin et 7 juil-\n",
    "let, et il appartiendra à tous de respecter\n",
    "son choix, d’accepter de consentir à sa volonté\n",
    "conformément à l’intangibilité du suffrage uni-\n",
    "versel\n",
    "Pour notre mouvement qui présente au pays\n",
    "un projet d’alternance politique, cette valida-\n",
    "tion démocratique de notre projet sera l’abou-\n",
    "tissement d’un long périple : après le moment\n",
    "des propositions puis de l’adhésion, viendra le\n",
    "temps de l’action.\n",
    "Le grand projet de redressement national au-\n",
    "quel nous nous engageons devant les électeurs\n",
    "s’articulera en deux phases, conformément à un\n",
    "calendrier réglementaire, législatif et constitu-\n",
    "tionnel parfaitement maîtrisé :input_t\n",
    "La première phase viendra répondre à\n",
    "-\n",
    "l’urgence sociale et sécuritaire : ces mesures\n",
    "interviendront dès l’élection d’une part avec la\n",
    "désignation d’un gouvernement et d’autre part\n",
    "dans le cadre d’une session extraordinaire ; ces\n",
    "textes seront adoptés par le parlement ou mis\n",
    "en œuvre par voie règlementaire jusqu’à l’au-\n",
    "tomne, date de la discussion budgétaire.\n",
    "-\n",
    "La seconde phase comprendra le débat\n",
    "budgétaire proprement dit qui intégrera no-\n",
    "tamment toute l’articulation fiscale puis, dans\n",
    "la foulée de ce vote annuel, une construction\n",
    "législative permettant de mettre en œuvre les\n",
    "réformes de fond.\n",
    "Jusqu’à l’automne : le temps de l’urgence\n",
    "Les mesures d’urgence concerneront les trois\n",
    "domaines que les électeurs ont jugés priori-\n",
    "taires. Ils se déploieront principalement par le\n",
    "biais de trois textes législatifs, textes d’urgence\n",
    "2\n",
    "sur la qualité de vie (pouvoir d’achat et santé), la\n",
    "sécurité et l’immigration.\n",
    "A ces travaux s’ajouteront le lancement des\n",
    "chantiers indispensables pour créer la base des\n",
    "réformes nécessaires à notre pays : un audit\n",
    "des comptes de la Nation pour connaître la ré-\n",
    "alité précise des finances publiques et d’autre\n",
    "part plusieurs consultations avec les corps in-\n",
    "termédiaires.\n",
    "Dès l’automne : le temps des réformes\n",
    "La phase de réforme commencera par le vote\n",
    "d’un premier budget : si évidemment, les prio-\n",
    "rités de ce budget prendront en compte les ré-\n",
    "sultats de l’audit des comptes de la Nation, il\n",
    "contiendra de nombreuses mesures fiscales ou\n",
    "financières qui s’inscrivent dans le projet pré-\n",
    "senté aux Français lors des élections présiden-\n",
    "tielles et européennes.\n",
    "Le gouvernement, en étroite liaison avec la ma-\n",
    "jorité parlementaire, s’attaquera aux grande ré-\n",
    "formes nécessaires au redressement de notre\n",
    "pays. Bien que jusqu’en 2027, cette législature\n",
    "se déroulera en cohabitation, nous utiliserons\n",
    "tous les leviers politiques et institutionnels que\n",
    "la Constitution donne au gouvernement et à sa\n",
    "majorité pour mettre un œuvre le projet voulu\n",
    "par le peuple français.\n",
    "...\n",
    "Transparence et concertation\n",
    "De très nombreux textes sont d’ores et déjà\n",
    "prêts. Les autres s’élaboreront au fil des concer-\n",
    "tations et d’un travail parlementaire libre pour\n",
    "lequel le pluralisme sera recherché, en dehors\n",
    "de tout esprit partisan, souvent réducteur et sté-\n",
    "rile.\n",
    "Un projet pour chacun et pour tous\n",
    "Ce projet vise à une remise en ordre dans nos\n",
    "rues et nos institutions, dans nos finances et\n",
    "notre environnement économique, dans nos\n",
    "écoles et nos vies. Il est pour des millions de\n",
    "Français de toutes origines, de toutes condi-\n",
    "tions, de toutes espérances, une formidable\n",
    "chance pour eux-mêmes et pour leurs enfants.\n",
    "Un engagement aextract_page_contentvec le peuple\n",
    "Le contrat que nous scellons avec le peuple\n",
    "français ne comporte aucune clause cachée,\n",
    "aucun non-dit, aucune surprise. Il est pour tous\n",
    "les Français une invitation à se joindre à un magnifique élan national que ce projet collectif\n",
    "formalise, celui de certitudes retrouvées, d’une \n",
    "ambition partagée, d’un avenir imaginé et décidé ensemble.\n",
    "Cette entreprise exaltante au service de l’uni-\n",
    "té et de la concorde civile affermira une so-\n",
    "ciété harmonieuse, respectueuse de tous. Elle\n",
    "prend corps autour d’un projet qui offrira à\n",
    "chacun toutes les opportunités d’épanouisse-\n",
    "ment et aux plus entreprenants la promesse\n",
    "de nouvelles conquêtes. Ce sera from typing import Listun projet qui\n",
    "émancipe les consciences et déverrouille les\n",
    "blocages, un projet qui libère les énergies créa-\n",
    "trices du pays, pour tendre au bonheur indivi-\n",
    "duel et à la prospérité collective.\n",
    "Il est fondé sur la liberté de chacun, le respect\n",
    "de tous. Il s’appuie sur une confiance dans cha-\n",
    "cun des Français et au-delà une foi inébranlable\n",
    "dans le peuple de France.\n",
    "Il témoigne de notre certitude de voir une ma-\n",
    "jorité de nos compatriotes adhérer à un idéal\n",
    "collectif pour consolider chaque jour davantage\n",
    "cette réalité fraternelle et solidaire qui s’appelle\n",
    "la Nation française.\n",
    "Chacun le comprendra. Notre projet tire sa force\n",
    "et sa crédibilité d’une cohérence intellectuelle\n",
    "et politique, de la raison et de l’ambition, de la\n",
    "fidélité au passé et d’une foi sans faille dans le\n",
    "futur. Il est surtout porté par le sentiment qui, de-\n",
    "puis l’origine, guide nos sentiments et nos pas,\n",
    "ce sentiment qui n’est rien d’autre que l’amouruments\n",
    "de la France et des Français.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "# List all file paths under the \"data\" folder\n",
    "data_folder = 'data'\n",
    "file_paths = [os.path.join(data_folder, file) for file in os.listdir(data_folder)]\n",
    "file_paths\n",
    "\n",
    "def init_file_path(data_folder: str) -> List[str]:\n",
    "    file_paths = [os.path.join(data_folder, file) for file in os.listdir(data_folder)]\n",
    "    return file_paths\n",
    "\n",
    "file_paths = init_file_path(data_folder)\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "# List all file paths under the \"data\" folder\n",
    "data_folder = 'data'\n",
    "def load_files(data_folder: str) -> List[Document]:\n",
    "    file_paths = init_file_path(data_folder)\n",
    "\n",
    "    loaded_docs = []\n",
    "\n",
    "    # Load file with styles\n",
    "    for file_path in file_paths:\n",
    "        loader =  PyPDFLoader(file_path)\n",
    "        loaded_docs.extend(loader.load())\n",
    "    return loaded_docs\n",
    "\n",
    "loaded_docs = load_files(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgramItem:\n",
    "    def __init__(self, content, file_path, page_number, topic, concreteness):\n",
    "        self.content = content\n",
    "        self.file_path = file_path\n",
    "        self.page_number = page_number\n",
    "        self.topic = topic\n",
    "        self.concreteness = concreteness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from typing import List\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "\n",
    "def create_semantic_splitter(text_splitter):\n",
    "    return lambda doc: [\n",
    "        ProgramItem(d.page_content, doc.metadata['source'], doc.metadata['page'], \"Unknown\", concreteness=0.5)\n",
    "        for d in text_splitter.create_documents([doc.page_content])\n",
    "    ]\n",
    "\n",
    "def display_items(title: str, items: List[ProgramItem]):\n",
    "    print(f\"{title} ({len(items)}) \\n\")\n",
    "    for i, item in enumerate(items):\n",
    "        print(f\"{i}({len(item.content)} - concreteness: {item.concreteness}, topic: {item.topic}, file: {item.file_path}, page: {item.page_number} ):{item.content[:120]} [...]\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = Document(test_input_text, metadata = {\"source\":\"test.pdf\", \"page\":1})\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from typing import List\n",
    "\n",
    "test_title = \"Default text splitter\"\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "semantic_split_page_content = create_semantic_splitter(text_splitter)\n",
    "items =  semantic_split_page_content(test_doc)\n",
    "display_items(test_title, items=items)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recherche sémantique utilisant \"SemanticChunker\" eclate la page en 3 bloc,  correspondant aux trois sections de texte... c'est correct, mais pas forcément ce que l'on veut en terme de découpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_title = \"Using standard_ deviation\"\n",
    "semantic_split_page_content = create_semantic_splitter(\n",
    "    SemanticChunker(\n",
    "        OpenAIEmbeddings(), \n",
    "        breakpoint_threshold_type=\"standard_deviation\"\n",
    "))\n",
    "display_items(test_title, items=semantic_split_page_content(test_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing is split...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_title = \"Interquantile splitter\"\n",
    "semantic_split_page_content = create_semantic_splitter(\n",
    "    SemanticChunker(\n",
    "        OpenAIEmbeddings(), \n",
    "        breakpoint_threshold_type=\"interquartile\"\n",
    "))\n",
    "display_items(test_title, items=semantic_split_page_content(test_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_title = \"Gradient splitter\"\n",
    "semantic_split_page_content = create_semantic_splitter(\n",
    "    SemanticChunker(\n",
    "        OpenAIEmbeddings(), \n",
    "        breakpoint_threshold_type=\"gradient\"\n",
    "))\n",
    "display_items(test_title, items=semantic_split_page_content(test_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_extraction_prompt_template = \"\"\"\n",
    "Dans le texte qui suit dans la balise \"<<<texte>>>, retrouver toutes les propositions d'actions.\n",
    "Ces propositions d'actions seront présentées sous forme de liste d'objects au format JSON, avec les élements entre crochets. \n",
    "chaque objet de la liste contiendra les champs:\n",
    "texte: contenu extrait du texte qui contient les propositions d'actions\n",
    "categorie: la catégorie de la proposition d'action courante, la valeur des catégorie doit être prise parmi les catégories suivantes: {categories}.\n",
    "precision: la précision de la proposition d'action courante, la valeur de la précision doit être comprise entre 0 et 1, 0 si l'action est totalement imprécise ou abstraite, 1 si cela correspond à une action précise (une action gouvernemtale, un décret, une nomionation, une loi, une proposition de loi, une proposition de budget, etc...).\n",
    "<<<texte>>>\n",
    "{input_text}\n",
    "<<</texte>>>\n",
    "\"\"\"\n",
    "category_list= [\"sécurité\", \"défense\", \"santé\", \"éducation\", \"culture\", \"finance\", \"justice\", \"écologie\", \"transport\", \"énergie\", \"agriculture\", \"économie\"]\n",
    "categories =  \", \".join(category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Define the schema\n",
    "schema = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"texte\": {\"type\": \"string\"},\n",
    "            \"categorie\": {\"type\": \"string\"},\n",
    "            \"precision\": {\"type\": \"number\", \"minimum\": 0, \"maximum\": 1}\n",
    "        },\n",
    "        \"required\": [\"texte\", \"categorie\", \"precision\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Configure the JsonOutputParser\n",
    "output_parser = JsonOutputParser(schema=schema)\n",
    "\n",
    "# Example input data\n",
    "input_data = '''\n",
    "[\n",
    "    {\"texte\": \"Le peuple va s’exprimer les 30 juin et 7 juillet\", \"categorie\": \"politique\", \"precision\": 0.9},\n",
    "    {\"texte\": \"Pour notre mouvement qui présente au pays un projet d’alternance politique\", \"categorie\": \"projet\", \"precision\": 0.8}\n",
    "]\n",
    "'''\n",
    "\n",
    "# Parse the data\n",
    "parsed_data = output_parser.parse(input_data)\n",
    "\n",
    "# Print the parsed data\n",
    "\n",
    "print(parsed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_categories(input_document: Document) -> List[ProgramItem]:\n",
    "    category_extraction_prompt = ChatPromptTemplate.from_template(category_extraction_prompt_template)\n",
    "    #category_extraction_prompt.format(categories=categories, text=test_input_text)\n",
    "    llm_model = \"gpt-4o\"\n",
    "    chat = ChatOpenAI(temperature=0, model=llm_model)\n",
    "    category_extraction_chain = category_extraction_prompt | chat\n",
    "    generated_text = category_extraction_prompt.format(categories=categories, input_text=test_input_text)\n",
    "    message = category_extraction_chain.invoke({\"categories\":categories, \"input_text\":test_input_text})\n",
    "    parsed_message = output_parser.parse(message.content)\n",
    "\n",
    "    print(f\"source:{input_document.metadata}\")\n",
    "    return [ProgramItem(content=item['texte'], topic=item['categorie'], file_path=input_document.metadata['source'], page_number=input_document.metadata['page'], concreteness=item['precision']) for item in parsed_message]\n",
    "\n",
    "test_program_item_list = extract_categories(test_doc)\n",
    "display_items(\"Open AI request on test data\",  test_program_item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_actions =  []\n",
    "# extract program actions from each document\n",
    "for doc in loaded_docs:\n",
    "    program_actions += extract_categories(doc)\n",
    "display_items(\"Analyzed documents\", program_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "with open('program_actions.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['content', 'topic', 'file_path', 'page_number','concreteness'])\n",
    "    for action in program_actions:\n",
    "        writer.writerow([action.content, action.topic, action.file_path, action.page_number, action.concreteness])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
